{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "052699cb-2f35-4164-8478-6b1a0b9f730e",
   "metadata": {},
   "source": [
    "## importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6504354a-56e3-40bd-8120-22ff61563a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer #used for text tokenization.\n",
    "from tensorflow.keras.layers import Embedding,LSTM,Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical #used to converting class vectors\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94dd0656-318a-455d-b547-e03ba2be89bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "file= pd.read_csv(\"text.txt\",sep='\\t')  # this use when we read tab seperated file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc5fe120-d0f0-465d-8b6e-3b7854f4a88c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>The Project Gutenberg eBook of Pride and Prejudice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This ebook is for the use of anyone anywhere i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>most other parts of the world at no cost and w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>whatsoever. You may copy it, give it away or r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>of the Project Gutenberg License included with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>at  If you are not located in the United States,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  The Project Gutenberg eBook of Pride and Prejudice\n",
       "0  This ebook is for the use of anyone anywhere i...\n",
       "1  most other parts of the world at no cost and w...\n",
       "2  whatsoever. You may copy it, give it away or r...\n",
       "3  of the Project Gutenberg License included with...\n",
       "4   at  If you are not located in the United States,"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19608099-2bc1-4849-a8f8-6c842604fed1",
   "metadata": {},
   "source": [
    "## load and pre-procces the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d1987d3-5b71-4208-9ed2-ce53ad2a2a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "file= open('text.txt','r',encoding ='utf8')\n",
    "#store file in list\n",
    "lines=[]\n",
    "for i in file:\n",
    "    lines.append(i)\n",
    "#lines\n",
    "# now we convert it into string\n",
    "data=\"\"\n",
    "for i in lines:\n",
    "    data= \" \".join(lines)\n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ded911c0-7f91-44e9-847e-a8f070c5148b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "864077"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we replace unnecessary stuff with space\n",
    "data =data.replace('\\n','').replace('\\r','').replace('\\ufeff','').replace('“','').replace('”','')\n",
    "data\n",
    "#now again we split our data then to string so we can remove unnecessary space\n",
    "data = data.split()\n",
    "data=\"  \".join(data)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b83616-c7ba-4386-99a0-a79594e04edb",
   "metadata": {},
   "source": [
    "## Apply Tokenization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9308d6ee-cc89-4c62-bacf-f4f63a366fca",
   "metadata": {},
   "source": [
    "##### fit_on_texts :  Updates internal vocabulary based on a list of texts. This method creates the vocabulary index based on word frequency. So if you give it something like, \"The cat sat on the mat.\" It will create a dictionary s.t. word_index[\"the\"] = 1; word_index[\"cat\"] = 2 it is word -> index dictionary so every word gets a unique integer value. 0 is reserved for padding. So lower integer means more frequent word (often the first few are stop words because they appear a lot).\n",
    "\n",
    "\r",
    "##### \n",
    "texts_to_sequences:  Transforms each text in texts to a sequence of integers. So it basically takes each word in the text and replaces it with its corresponding integer value from the word_index dictionary. Nothing more, nothing less, certainly no magic involved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5e7f0c5-ed36-4388-a9b6-cb69d3fa1311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131175"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([data])  #update the internal vocabulary of the tokenizer\n",
    "#saveing the tokenizer for predict function\n",
    "pickle.dump(tokenizer,open('token.pkl','wb'))\n",
    "# to get the first sequence (assuming there's only one sequence in the list).\n",
    "sequence_data = tokenizer.texts_to_sequences([data])[0]\n",
    "len(sequence_data)\n",
    "# hence we notic the that len is decreases  because in ext file so manay words are \n",
    "# repeated and each unique word get one numeric representaion\n",
    "#print(sequence_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "190c5747-1d69-4a2d-aab4-c7e7b147adf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7254"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size =len(tokenizer.word_index) + 1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "797a259f-43c6-4123-a924-88a0dc0326cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1,  181,  403, 1000],\n",
       "       [ 181,  403, 1000,    3],\n",
       "       [ 403, 1000,    3,  298],\n",
       "       [1000,    3,  298,    4],\n",
       "       [   3,  298,    4,  946],\n",
       "       [ 298,    4,  946,   41],\n",
       "       [   4,  946,   41, 1000],\n",
       "       [ 946,   41, 1000,   23],\n",
       "       [  41, 1000,   23,   21],\n",
       "       [1000,   23,   21,    1]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences =[]\n",
    "# since we are training for the pridiction of next_words after sequence of 3 words\n",
    "for i in range(3, len(sequence_data)):\n",
    "    words = sequence_data[i-3:i+1]\n",
    "    sequences.append(words)\n",
    "sequences = np.array(sequences)\n",
    "# lets print first 10 sequences\n",
    "sequences[:10]\n",
    "# as we can below in 2d array the first 3 element will be input and 4 will be the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d4a8b47-602b-4beb-afbd-54be64be9fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we seperate input and output\n",
    "x=[]\n",
    "y=[]\n",
    "\n",
    "for i in sequences:\n",
    "    x.append(i[0:3])\n",
    "    y.append(i[3])\n",
    "x=np.array(x)\n",
    "y=np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc5ea544-cf34-4b92-88a1-27b26b9fdd1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131172"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50593f2a-3326-47e9-b57e-23b126cc257d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89b0c60b-be9b-4b63-b48e-d595d58903f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test =train_test_split(x,y,test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d765ca0e-98e1-4b76-822d-669a281d166c",
   "metadata": {},
   "source": [
    "## Createing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c419d3c3-faf0-4d64-a593-1699e31cd04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ag800\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 3, 10)             72540     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 3, 1000)           4044000   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 1000)              8004000   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1000)              1001000   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7254)              7261254   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20382794 (77.75 MB)\n",
      "Trainable params: 20382794 (77.75 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#input_length =3\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 10, input_length=3))\n",
    "model.add(LSTM(1000, return_sequences=True))\n",
    "model.add(LSTM(1000))\n",
    "model.add(Dense(1000, activation=\"relu\"))\n",
    "model.add(Dense(vocab_size, activation=\"softmax\"))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a18131-645d-4046-9ace-35de12df195a",
   "metadata": {},
   "source": [
    "## Training  the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fee47b92-e5c6-4e66-a02f-f66e82902c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:From C:\\Users\\ag800\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ag800\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1640/1640 [==============================] - ETA: 0s - loss: 6.3137 - accuracy: 0.0541\n",
      "Epoch 1: loss improved from inf to 6.31369, saving model to next_words.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ag800\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1640/1640 [==============================] - 666s 400ms/step - loss: 6.3137 - accuracy: 0.0541\n",
      "Epoch 2/50\n",
      "1640/1640 [==============================] - ETA: 0s - loss: 5.6870 - accuracy: 0.0982\n",
      "Epoch 2: loss improved from 6.31369 to 5.68695, saving model to next_words.h5\n",
      "1640/1640 [==============================] - 697s 425ms/step - loss: 5.6870 - accuracy: 0.0982\n",
      "Epoch 3/50\n",
      "1640/1640 [==============================] - ETA: 0s - loss: 5.3524 - accuracy: 0.1155\n",
      "Epoch 3: loss improved from 5.68695 to 5.35237, saving model to next_words.h5\n",
      "1640/1640 [==============================] - 683s 417ms/step - loss: 5.3524 - accuracy: 0.1155\n",
      "Epoch 4/50\n",
      "1640/1640 [==============================] - ETA: 0s - loss: 5.1252 - accuracy: 0.1285\n",
      "Epoch 4: loss improved from 5.35237 to 5.12519, saving model to next_words.h5\n",
      "1640/1640 [==============================] - 692s 422ms/step - loss: 5.1252 - accuracy: 0.1285\n",
      "Epoch 5/50\n",
      "1640/1640 [==============================] - ETA: 0s - loss: 4.9173 - accuracy: 0.1397\n",
      "Epoch 5: loss improved from 5.12519 to 4.91728, saving model to next_words.h5\n",
      "1640/1640 [==============================] - 684s 417ms/step - loss: 4.9173 - accuracy: 0.1397\n",
      "Epoch 6/50\n",
      "1640/1640 [==============================] - ETA: 0s - loss: 4.7069 - accuracy: 0.1503\n",
      "Epoch 6: loss improved from 4.91728 to 4.70690, saving model to next_words.h5\n",
      "1640/1640 [==============================] - 2634s 2s/step - loss: 4.7069 - accuracy: 0.1503\n",
      "Epoch 7/50\n",
      "1640/1640 [==============================] - ETA: 0s - loss: 4.4896 - accuracy: 0.1604\n",
      "Epoch 7: loss improved from 4.70690 to 4.48965, saving model to next_words.h5\n",
      "1640/1640 [==============================] - 644s 392ms/step - loss: 4.4896 - accuracy: 0.1604\n",
      "Epoch 8/50\n",
      "1640/1640 [==============================] - ETA: 0s - loss: 4.2696 - accuracy: 0.1702\n",
      "Epoch 8: loss improved from 4.48965 to 4.26960, saving model to next_words.h5\n",
      "1640/1640 [==============================] - 667s 407ms/step - loss: 4.2696 - accuracy: 0.1702\n",
      "Epoch 9/50\n",
      "1640/1640 [==============================] - ETA: 0s - loss: 4.0384 - accuracy: 0.1833\n",
      "Epoch 9: loss improved from 4.26960 to 4.03836, saving model to next_words.h5\n",
      "1640/1640 [==============================] - 712s 434ms/step - loss: 4.0384 - accuracy: 0.1833\n",
      "Epoch 10/50\n",
      "1640/1640 [==============================] - ETA: 0s - loss: 3.8022 - accuracy: 0.2026\n",
      "Epoch 10: loss improved from 4.03836 to 3.80225, saving model to next_words.h5\n",
      "1640/1640 [==============================] - 980s 598ms/step - loss: 3.8022 - accuracy: 0.2026\n",
      "Epoch 11/50\n",
      "1640/1640 [==============================] - ETA: 0s - loss: 3.5637 - accuracy: 0.2271\n",
      "Epoch 11: loss improved from 3.80225 to 3.56370, saving model to next_words.h5\n",
      "1640/1640 [==============================] - 651s 397ms/step - loss: 3.5637 - accuracy: 0.2271\n",
      "Epoch 12/50\n",
      "1640/1640 [==============================] - ETA: 0s - loss: 3.3270 - accuracy: 0.2551\n",
      "Epoch 12: loss improved from 3.56370 to 3.32702, saving model to next_words.h5\n",
      "1640/1640 [==============================] - 649s 396ms/step - loss: 3.3270 - accuracy: 0.2551\n",
      "Epoch 13/50\n",
      "1640/1640 [==============================] - ETA: 0s - loss: 3.0911 - accuracy: 0.2885\n",
      "Epoch 13: loss improved from 3.32702 to 3.09112, saving model to next_words.h5\n",
      "1640/1640 [==============================] - 1235s 753ms/step - loss: 3.0911 - accuracy: 0.2885\n",
      "Epoch 14/50\n",
      "1640/1640 [==============================] - ETA: 0s - loss: 2.8612 - accuracy: 0.3250\n",
      "Epoch 14: loss improved from 3.09112 to 2.86118, saving model to next_words.h5\n",
      "1640/1640 [==============================] - 627s 382ms/step - loss: 2.8612 - accuracy: 0.3250\n",
      "Epoch 15/50\n",
      "1640/1640 [==============================] - ETA: 0s - loss: 2.6225 - accuracy: 0.3668\n",
      "Epoch 15: loss improved from 2.86118 to 2.62246, saving model to next_words.h5\n",
      "1640/1640 [==============================] - 622s 380ms/step - loss: 2.6225 - accuracy: 0.3668\n",
      "Epoch 16/50\n",
      "1640/1640 [==============================] - ETA: 0s - loss: 2.3820 - accuracy: 0.4105\n",
      "Epoch 16: loss improved from 2.62246 to 2.38204, saving model to next_words.h5\n",
      "1640/1640 [==============================] - 625s 381ms/step - loss: 2.3820 - accuracy: 0.4105\n",
      "Epoch 17/50\n",
      "1640/1640 [==============================] - ETA: 0s - loss: 2.1445 - accuracy: 0.4588\n",
      "Epoch 17: loss improved from 2.38204 to 2.14454, saving model to next_words.h5\n",
      "1640/1640 [==============================] - 622s 379ms/step - loss: 2.1445 - accuracy: 0.4588\n",
      "Epoch 18/50\n",
      "1640/1640 [==============================] - ETA: 0s - loss: 1.9144 - accuracy: 0.5083\n",
      "Epoch 18: loss improved from 2.14454 to 1.91441, saving model to next_words.h5\n",
      "1640/1640 [==============================] - 615s 375ms/step - loss: 1.9144 - accuracy: 0.5083\n",
      "Epoch 19/50\n",
      "1640/1640 [==============================] - ETA: 0s - loss: 1.6963 - accuracy: 0.5573\n",
      "Epoch 19: loss improved from 1.91441 to 1.69633, saving model to next_words.h5\n",
      "1640/1640 [==============================] - 618s 377ms/step - loss: 1.6963 - accuracy: 0.5573\n",
      "Epoch 20/50\n",
      "1640/1640 [==============================] - ETA: 0s - loss: 1.5017 - accuracy: 0.6050\n",
      "Epoch 20: loss improved from 1.69633 to 1.50168, saving model to next_words.h5\n",
      "1640/1640 [==============================] - 617s 376ms/step - loss: 1.5017 - accuracy: 0.6050\n",
      "Epoch 21/50\n",
      "1640/1640 [==============================] - ETA: 0s - loss: 1.3287 - accuracy: 0.6481\n",
      "Epoch 21: loss improved from 1.50168 to 1.32873, saving model to next_words.h5\n",
      "1640/1640 [==============================] - 611s 372ms/step - loss: 1.3287 - accuracy: 0.6481\n",
      "Epoch 22/50\n",
      "1640/1640 [==============================] - ETA: 0s - loss: 1.1846 - accuracy: 0.6847\n",
      "Epoch 22: loss improved from 1.32873 to 1.18459, saving model to next_words.h5\n",
      "1640/1640 [==============================] - 615s 375ms/step - loss: 1.1846 - accuracy: 0.6847\n",
      "Epoch 23/50\n",
      "1640/1640 [==============================] - ETA: 0s - loss: 1.0604 - accuracy: 0.7170\n",
      "Epoch 23: loss improved from 1.18459 to 1.06043, saving model to next_words.h5\n",
      "1640/1640 [==============================] - 614s 374ms/step - loss: 1.0604 - accuracy: 0.7170\n",
      "Epoch 24/50\n",
      "1640/1640 [==============================] - ETA: 0s - loss: 0.9644 - accuracy: 0.7432\n",
      "Epoch 24: loss improved from 1.06043 to 0.96437, saving model to next_words.h5\n",
      "1640/1640 [==============================] - 616s 376ms/step - loss: 0.9644 - accuracy: 0.7432\n",
      "Epoch 25/50\n",
      "1640/1640 [==============================] - ETA: 0s - loss: 0.8861 - accuracy: 0.7632\n",
      "Epoch 25: loss improved from 0.96437 to 0.88606, saving model to next_words.h5\n",
      "1640/1640 [==============================] - 615s 375ms/step - loss: 0.8861 - accuracy: 0.7632\n",
      "Epoch 26/50\n",
      "1640/1640 [==============================] - ETA: 0s - loss: 0.8267 - accuracy: 0.7793\n",
      "Epoch 26: loss improved from 0.88606 to 0.82670, saving model to next_words.h5\n",
      "1640/1640 [==============================] - 614s 374ms/step - loss: 0.8267 - accuracy: 0.7793\n",
      "Epoch 27/50\n",
      "1640/1640 [==============================] - ETA: 0s - loss: 0.7789 - accuracy: 0.7888\n",
      "Epoch 27: loss improved from 0.82670 to 0.77893, saving model to next_words.h5\n",
      "1640/1640 [==============================] - 614s 374ms/step - loss: 0.7789 - accuracy: 0.7888\n",
      "Epoch 28/50\n",
      "1640/1640 [==============================] - ETA: 0s - loss: 0.7331 - accuracy: 0.8004\n",
      "Epoch 28: loss improved from 0.77893 to 0.73314, saving model to next_words.h5\n",
      "1640/1640 [==============================] - 614s 374ms/step - loss: 0.7331 - accuracy: 0.8004\n",
      "Epoch 29/50\n",
      "1640/1640 [==============================] - ETA: 0s - loss: 0.7019 - accuracy: 0.8069\n",
      "Epoch 29: loss improved from 0.73314 to 0.70193, saving model to next_words.h5\n",
      "1640/1640 [==============================] - 614s 374ms/step - loss: 0.7019 - accuracy: 0.8069\n",
      "Epoch 30/50\n",
      "1640/1640 [==============================] - ETA: 0s - loss: 0.6750 - accuracy: 0.8115\n",
      "Epoch 30: loss improved from 0.70193 to 0.67497, saving model to next_words.h5\n",
      "1640/1640 [==============================] - 627s 382ms/step - loss: 0.6750 - accuracy: 0.8115\n",
      "Epoch 31/50\n",
      "1640/1640 [==============================] - ETA: 0s - loss: 0.6511 - accuracy: 0.8170\n",
      "Epoch 31: loss improved from 0.67497 to 0.65106, saving model to next_words.h5\n",
      "1640/1640 [==============================] - 626s 382ms/step - loss: 0.6511 - accuracy: 0.8170\n",
      "Epoch 32/50\n",
      "1640/1640 [==============================] - ETA: 0s - loss: 0.6270 - accuracy: 0.8197\n",
      "Epoch 32: loss improved from 0.65106 to 0.62697, saving model to next_words.h5\n",
      "1640/1640 [==============================] - 620s 378ms/step - loss: 0.6270 - accuracy: 0.8197\n",
      "Epoch 33/50\n",
      "1640/1640 [==============================] - ETA: 0s - loss: 0.6098 - accuracy: 0.8239\n",
      "Epoch 33: loss improved from 0.62697 to 0.60980, saving model to next_words.h5\n",
      "1640/1640 [==============================] - 616s 376ms/step - loss: 0.6098 - accuracy: 0.8239\n",
      "Epoch 34/50\n",
      "1640/1640 [==============================] - ETA: 0s - loss: 0.5953 - accuracy: 0.8250\n",
      "Epoch 34: loss improved from 0.60980 to 0.59535, saving model to next_words.h5\n",
      "1640/1640 [==============================] - 616s 376ms/step - loss: 0.5953 - accuracy: 0.8250\n",
      "Epoch 35/50\n",
      "1640/1640 [==============================] - ETA: 0s - loss: 0.5817 - accuracy: 0.8267\n",
      "Epoch 35: loss improved from 0.59535 to 0.58172, saving model to next_words.h5\n",
      "1640/1640 [==============================] - 616s 375ms/step - loss: 0.5817 - accuracy: 0.8267\n",
      "Epoch 36/50\n",
      "1640/1640 [==============================] - ETA: 0s - loss: 0.5672 - accuracy: 0.8291\n",
      "Epoch 36: loss improved from 0.58172 to 0.56716, saving model to next_words.h5\n",
      "1640/1640 [==============================] - 616s 376ms/step - loss: 0.5672 - accuracy: 0.8291\n",
      "Epoch 37/50\n",
      "1640/1640 [==============================] - ETA: 0s - loss: 0.5578 - accuracy: 0.8313\n",
      "Epoch 37: loss improved from 0.56716 to 0.55781, saving model to next_words.h5\n",
      "1640/1640 [==============================] - 627s 382ms/step - loss: 0.5578 - accuracy: 0.8313\n",
      "Epoch 38/50\n",
      "1640/1640 [==============================] - ETA: 0s - loss: 0.5430 - accuracy: 0.8315\n",
      "Epoch 38: loss improved from 0.55781 to 0.54298, saving model to next_words.h5\n",
      "1640/1640 [==============================] - 649s 396ms/step - loss: 0.5430 - accuracy: 0.8315\n",
      "Epoch 39/50\n",
      "1640/1640 [==============================] - ETA: 0s - loss: 0.5350 - accuracy: 0.8321\n",
      "Epoch 39: loss improved from 0.54298 to 0.53496, saving model to next_words.h5\n",
      "1640/1640 [==============================] - 645s 393ms/step - loss: 0.5350 - accuracy: 0.8321\n",
      "Epoch 40/50\n",
      "1640/1640 [==============================] - ETA: 0s - loss: 0.5229 - accuracy: 0.8334\n",
      "Epoch 40: loss improved from 0.53496 to 0.52287, saving model to next_words.h5\n",
      "1640/1640 [==============================] - 645s 393ms/step - loss: 0.5229 - accuracy: 0.8334\n",
      "Epoch 41/50\n",
      "1640/1640 [==============================] - ETA: 0s - loss: 0.5152 - accuracy: 0.8345\n",
      "Epoch 41: loss improved from 0.52287 to 0.51521, saving model to next_words.h5\n",
      "1640/1640 [==============================] - 645s 393ms/step - loss: 0.5152 - accuracy: 0.8345\n",
      "Epoch 42/50\n",
      "1640/1640 [==============================] - ETA: 0s - loss: 0.5074 - accuracy: 0.8357\n",
      "Epoch 42: loss improved from 0.51521 to 0.50744, saving model to next_words.h5\n",
      "1640/1640 [==============================] - 646s 394ms/step - loss: 0.5074 - accuracy: 0.8357\n",
      "Epoch 43/50\n",
      "1640/1640 [==============================] - ETA: 0s - loss: 0.5007 - accuracy: 0.8352\n",
      "Epoch 43: loss improved from 0.50744 to 0.50071, saving model to next_words.h5\n",
      "1640/1640 [==============================] - 648s 395ms/step - loss: 0.5007 - accuracy: 0.8352\n",
      "Epoch 44/50\n",
      "1640/1640 [==============================] - ETA: 0s - loss: 0.4941 - accuracy: 0.8355\n",
      "Epoch 44: loss improved from 0.50071 to 0.49414, saving model to next_words.h5\n",
      "1640/1640 [==============================] - 646s 394ms/step - loss: 0.4941 - accuracy: 0.8355\n",
      "Epoch 45/50\n",
      "1640/1640 [==============================] - ETA: 0s - loss: 0.4864 - accuracy: 0.8374\n",
      "Epoch 45: loss improved from 0.49414 to 0.48637, saving model to next_words.h5\n",
      "1640/1640 [==============================] - 646s 394ms/step - loss: 0.4864 - accuracy: 0.8374\n",
      "Epoch 46/50\n",
      "1640/1640 [==============================] - ETA: 0s - loss: 0.4801 - accuracy: 0.8360\n",
      "Epoch 46: loss improved from 0.48637 to 0.48008, saving model to next_words.h5\n",
      "1640/1640 [==============================] - 646s 394ms/step - loss: 0.4801 - accuracy: 0.8360\n",
      "Epoch 47/50\n",
      "1640/1640 [==============================] - ETA: 0s - loss: 0.4757 - accuracy: 0.8362\n",
      "Epoch 47: loss improved from 0.48008 to 0.47566, saving model to next_words.h5\n",
      "1640/1640 [==============================] - 664s 405ms/step - loss: 0.4757 - accuracy: 0.8362\n",
      "Epoch 48/50\n",
      "1640/1640 [==============================] - ETA: 0s - loss: 0.4682 - accuracy: 0.8373\n",
      "Epoch 48: loss improved from 0.47566 to 0.46823, saving model to next_words.h5\n",
      "1640/1640 [==============================] - 653s 398ms/step - loss: 0.4682 - accuracy: 0.8373\n",
      "Epoch 49/50\n",
      "1640/1640 [==============================] - ETA: 0s - loss: 0.4575 - accuracy: 0.8393\n",
      "Epoch 49: loss improved from 0.46823 to 0.45745, saving model to next_words.h5\n",
      "1640/1640 [==============================] - 647s 395ms/step - loss: 0.4575 - accuracy: 0.8393\n",
      "Epoch 50/50\n",
      "1640/1640 [==============================] - ETA: 0s - loss: 0.4587 - accuracy: 0.8383\n",
      "Epoch 50: loss did not improve from 0.45745\n",
      "1640/1640 [==============================] - 646s 394ms/step - loss: 0.4587 - accuracy: 0.8383\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1d671599710>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will use ModelCheckpoint which save our model and wait at some intervals \n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"next_words.h5\",monitor=\"loss\",verbose=1,save_best_only =True)\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=\"Adam\",\n",
    "    metrics=['accuracy'])\n",
    "model.fit(x_train,y_train,batch_size=64,callbacks=[checkpoint],epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43066d9d-322c-41fa-988b-f4c5a978fc96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your line:  The Project Gutenberg eBook of\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Gutenberg', 'eBook', 'of']\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "pride\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your line:  i am your friend \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['your', 'friend', '']\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "to\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your line:  how can you abuse your own\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abuse', 'your', 'own']\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "but\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your line:  He could not help seeing that you were about five times as\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['five', 'times', 'as']\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "she\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import pickle\n",
    " \n",
    "# Load the model and tokenizer\n",
    "model = load_model('next_words.h5')\n",
    "tokenizer = pickle.load(open('token.pkl', 'rb'))\n",
    " \n",
    "def Predict_Next_Words(model, tokenizer, text):\n",
    " \n",
    "  sequence = tokenizer.texts_to_sequences([text])\n",
    "  sequence = np.array(sequence)\n",
    "  preds = np.argmax(model.predict(sequence))\n",
    "  predicted_word = \"\"\n",
    "   \n",
    "  for key, value in tokenizer.word_index.items():\n",
    "      if value == preds:\n",
    "          predicted_word = key\n",
    "          break\n",
    "   \n",
    "  print(predicted_word)\n",
    "  return predicted_word\n",
    "while(True):\n",
    "  text = input(\"Enter your line: \")\n",
    "   \n",
    "  if text == \"0\":\n",
    "      print(\"Execution completed.....\")\n",
    "      break\n",
    "   \n",
    "  else:\n",
    "      try:\n",
    "          text = text.split(\" \")\n",
    "          text = text[-3:]\n",
    "          print(text)\n",
    "         \n",
    "          Predict_Next_Words(model, tokenizer, text)\n",
    "           \n",
    "      except Exception as e:\n",
    "        print(\"Error occurred: \",e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3c562f-5542-4261-886c-891831f237f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
